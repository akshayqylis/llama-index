{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc98b9-5c00-4c2c-8f5b-e03391e5914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "from vllmpoint import get_vllm_embedder, get_vllm_llm\n",
    "\n",
    "import logging\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91a71ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.INFO\n",
    ")  # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "241f2e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_vllm_llm()\n",
    "embed_model = get_vllm_embedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51827fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88496e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://g3.ai.qylis.com:7000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://g3.ai.qylis.com:7000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://g3.ai.qylis.com:7000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://g3.ai.qylis.com:7000/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Simple query by indexing\n",
    "# TODO: Try multimedia inputs like mp3 and mp4\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"feedback.docx\"]\n",
    ").load_data()\n",
    "feedback_index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e39c2b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://g3.ai.qylis.com:7000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://g3.ai.qylis.com:7000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://g3.ai.qylis.com:7000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://g3.ai.qylis.com:7000/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://g3.ai.qylis.com:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://g3.ai.qylis.com:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://g3.ai.qylis.com:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST http://g3.ai.qylis.com:8000/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the feedback about? Give me names.\"\n",
    "query_engine = feedback_index.as_query_engine()\n",
    "answer = query_engine.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d80abc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: ec5fd2e7-010a-4a7e-8fb5-36707a3e5bc3): Interview Feedback Form - Qylis\n",
      "\n",
      "Section 1: Candidate Details \n",
      "\n",
      "Name of Candidate   : ______ ____...\n",
      "Query was: What is the feedback about? Give me names.\n",
      "Answer was: The feedback is about an interview for a Data Science position. The names mentioned are Sohel and Akshay.\n"
     ]
    }
   ],
   "source": [
    "print(answer.get_formatted_sources())\n",
    "print(\"Query was:\", query)\n",
    "print(\"Answer was:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00360b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.468332 seconds\n",
      "Retrying request to /chat/completions in 0.468332 seconds\n",
      "Retrying request to /chat/completions in 0.468332 seconds\n",
      "Retrying request to /chat/completions in 0.468332 seconds\n"
     ]
    }
   ],
   "source": [
    "# Summarization\n",
    "summary_index = SummaryIndex.from_documents(documents)\n",
    "\n",
    "query_engine = summary_index.as_query_engine(response_mode=\"tree_summarize\", streaming=True)\n",
    "response = query_engine.query(\"<summarization_query>\")\n",
    "response.print_response_stream()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d071018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"paul_graham_essay.txt\"]\n",
    ").load_data()\n",
    "essay_index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# Define query engines and tools\n",
    "tool1 = QueryEngineTool.from_defaults(\n",
    "    query_engine=feedback_index.as_query_engine(),\n",
    "    description=\"Use this query engine for feedback form.\",\n",
    "    # description=\"Use this query engine for an English essay.\", Switch\n",
    ")\n",
    "tool2 = QueryEngineTool.from_defaults(\n",
    "    query_engine=essay_index.as_query_engine(),\n",
    "    description=\"Use this query engine for an English essay.\",\n",
    "    # description=\"Use this query engine for feedback form.\", Switch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb0c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get as chat. Keeps track of conversation history\n",
    "chat_engine = feedback_index.as_chat_engine()\n",
    "chat1 = \"Who is the interview candidate?\"\n",
    "response1 = chat_engine.chat(chat1)\n",
    "print('Response1:', response1)\n",
    "chat2 = \"Who is the interviewer?\"\n",
    "response2 = chat_engine.chat(chat2)\n",
    "print('Response2:', response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc996f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat3 = \"Give me the summary of the feedback?\"\n",
    "response3 = chat_engine.chat(chat3)\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interactive chat\n",
    "chat_engine = feedback_index.as_chat_engine()\n",
    "chat_engine.chat_repl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382698e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
